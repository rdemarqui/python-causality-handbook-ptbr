{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 - Estimação Duplamente Robusta\n",
    "\n",
    "## Não Coloque Todos os Ovos na Mesma Cesta\n",
    "\n",
    "Aprendemos como utilizar a regressão linear e o peso da pontuação de propensão para estimar $E[Y|T=1] - E[Y|T=0] | X$. Mas qual devemos usar e quando? Em caso de dúvida, use ambos! A Estimação Duplamente Robusta é uma maneira de combinar a pontuação de propensão e a regressão linear de forma que você não precise depender exclusivamente de uma delas.\n",
    "\n",
    "Para entender como isso funciona, vamos considerar o experimento da mentalidade. Trata-se de um estudo randomizado realizado em escolas públicas dos Estados Unidos, com o objetivo de avaliar o impacto da mentalidade de crescimento. O procedimento consiste em fornecer aos alunos um seminário, promovido pela escola, para fomentar uma mentalidade de crescimento. Em seguida, eles acompanham os alunos durante seus anos universitários para medir seu desempenho acadêmico. Essa medição é compilada em uma pontuação de realização e padronizada. Os dados reais deste estudo não estão disponíveis publicamente para preservar a privacidade dos alunos. No entanto, temos um conjunto de dados simulado com as mesmas propriedades estatísticas fornecidas por [Athey and Wager](https://arxiv.org/pdf/1902.07409.pdf), e usaremos esse conjunto simulado no lugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.498438Z",
     "start_time": "2023-03-14T11:05:46.659452Z"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "style.use(\"fivethirtyeight\")\n",
    "pd.set_option(\"display.max_columns\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.535134Z",
     "start_time": "2023-03-14T11:05:50.500165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schoolid</th>\n",
       "      <th>intervention</th>\n",
       "      <th>achievement_score</th>\n",
       "      <th>...</th>\n",
       "      <th>school_ethnic_minority</th>\n",
       "      <th>school_poverty</th>\n",
       "      <th>school_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>1.480828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515202</td>\n",
       "      <td>-0.169849</td>\n",
       "      <td>0.173954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3435</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.987277</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9963</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.152340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875012</td>\n",
       "      <td>-0.724801</td>\n",
       "      <td>0.761781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4488</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.358336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315755</td>\n",
       "      <td>0.054586</td>\n",
       "      <td>1.862187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1.360920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033161</td>\n",
       "      <td>-0.982274</td>\n",
       "      <td>1.591641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      schoolid  intervention  achievement_score  ...  school_ethnic_minority  \\\n",
       "259         73             1           1.480828  ...               -0.515202   \n",
       "3435        76             0          -0.987277  ...               -1.310927   \n",
       "9963         4             0          -0.152340  ...                0.875012   \n",
       "4488        67             0           0.358336  ...                0.315755   \n",
       "2637        16             1           1.360920  ...               -0.033161   \n",
       "\n",
       "      school_poverty  school_size  \n",
       "259        -0.169849     0.173954  \n",
       "3435        0.224077    -0.426757  \n",
       "9963       -0.724801     0.761781  \n",
       "4488        0.054586     1.862187  \n",
       "2637       -0.982274     1.591641  \n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/learning_mindset.csv\")\n",
    "data.sample(5, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora o estudo tenha sido randomizado, parece que os dados não estão livres de confundidores. Uma possível razão é que a variável de tratamento é medida pela participação do aluno no seminário. Assim, embora a oportunidade de participação tenha sido aleatória, a participação em si não o foi. Estamos lidando com um caso de cumprimento parcial aqui. Uma evidência disso é como a expectativa de sucesso do aluno está correlacionada com a participação no seminário. Alunos com expectativas auto-relatadas mais altas têm maior probabilidade de terem participado do seminário sobre mentalidade de crescimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.546638Z",
     "start_time": "2023-03-14T11:05:50.538742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "success_expect\n",
       "1    0.271739\n",
       "2    0.265957\n",
       "3    0.294118\n",
       "4    0.271617\n",
       "5    0.311070\n",
       "6    0.354287\n",
       "7    0.362319\n",
       "Name: intervention, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"success_expect\")[\"intervention\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sabemos agora, podemos ajustar isso usando uma regressão linear ou estimando um modelo de pontuação de propensão com uma regressão logística. Antes de fazer isso, no entanto, precisamos converter as variáveis categóricas em variáveis dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.559709Z",
     "start_time": "2023-03-14T11:05:50.548969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10391, 32)\n"
     ]
    }
   ],
   "source": [
    "categ = [\"ethnicity\", \"gender\", \"school_urbanicity\"]\n",
    "cont = [\"school_mindset\", \"school_achievement\", \"school_ethnic_minority\", \"school_poverty\", \"school_size\"]\n",
    "\n",
    "data_with_categ = pd.concat([\n",
    "    data.drop(columns=categ), # dataset without the categorical features\n",
    "    pd.get_dummies(data[categ], columns=categ, drop_first=False) # categorical features converted to dummies\n",
    "], axis=1)\n",
    "\n",
    "print(data_with_categ.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos agora prontos para compreender como funciona a estimação duplamente robusta.\n",
    "\n",
    "## Estimação Duplamente Robusta\n",
    "\n",
    "![img](./data/img/doubly-robust/double.png)\n",
    "\n",
    "Em vez de derivar o estimador, vou primeiro mostrá-lo e só então explicar por que é incrível.\n",
    "\n",
    "$\n",
    "\\hat{ATE} = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_i(Y_i - \\hat{\\mu_1}(X_i))}{\\hat{P}(X_i)} + \\hat{\\mu_1}(X_i) \\bigg) - \\frac{1}{N}\\sum \\bigg( \\dfrac{(1-T_i)(Y_i - \\hat{\\mu_0}(X_i))}{1-\\hat{P}(X_i)} + \\hat{\\mu_0}(X_i) \\bigg)\n",
    "$\n",
    "\n",
    "onde $\\hat{P}(x)$ é uma estimativa da pontuação de propensão (usando regressão logística, por exemplo), $\\hat{\\mu_1}(x)$ é uma estimativa de $E[Y|X, T=1]$ (usando regressão linear, por exemplo), e $\\hat{\\mu_0}(x)$ é uma estimativa de $E[Y|X, T=0]$. Como você já deve ter imaginado, a primeira parte do estimador duplamente robusto estima $E[Y_1]$ e a segunda parte estima $E[Y_0]$. Vamos examinar a primeira parte, pois toda a intuição também se aplicará à segunda parte por analogia.\n",
    "\n",
    "Como sei que esta fórmula pode parecer assustadora à primeira vista (mas não se preocupe, verá que é super simples), vou primeiro mostrar como codificar este estimador. Tenho a sensação de que algumas pessoas se assustam menos com código do que com fórmulas. Vamos ver como este estimador funciona na prática, certo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.566875Z",
     "start_time": "2023-03-14T11:05:50.562600Z"
    }
   },
   "outputs": [],
   "source": [
    "def doubly_robust(df, X, T, Y):\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(df[X], df[T]).predict_proba(df[X])[:, 1]\n",
    "    mu0 = LinearRegression().fit(df.query(f\"{T}==0\")[X], df.query(f\"{T}==0\")[Y]).predict(df[X])\n",
    "    mu1 = LinearRegression().fit(df.query(f\"{T}==1\")[X], df.query(f\"{T}==1\")[Y]).predict(df[X])\n",
    "    return (\n",
    "        np.mean(df[T]*(df[Y] - mu1)/ps + mu1) -\n",
    "        np.mean((1-df[T])*(df[Y] - mu0)/(1-ps) + mu0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:05:50.753508Z",
     "start_time": "2023-03-14T11:05:50.568291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38822121767832457"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 'intervention'\n",
    "Y = 'achievement_score'\n",
    "X = data_with_categ.columns.drop(['schoolid', T, Y])\n",
    "\n",
    "doubly_robust(data_with_categ, X, T, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O estimador duplamente robusto está indicando que devemos esperar que os indivíduos que participaram do seminário sobre mentalidade estejam 0.388 desvios padrão acima de seus colegas não tratados, em termos de realizações. Mais uma vez, podemos utilizar a técnica de amostras com reposição *(bootstrap, em inglês)* para construir intervalos de confiança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.493875Z",
     "start_time": "2023-03-14T11:05:50.757649Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed # for parallel processing\n",
    "\n",
    "np.random.seed(88)\n",
    "# run 1000 bootstrap samples\n",
    "bootstrap_sample = 1000\n",
    "ates = Parallel(n_jobs=4)(delayed(doubly_robust)(data_with_categ.sample(frac=1, replace=True), X, T, Y)\n",
    "                          for _ in range(bootstrap_sample))\n",
    "ates = np.array(ates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.500840Z",
     "start_time": "2023-03-14T11:06:30.496065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE 95% CI: (0.35364752721776144, 0.41978441342477585)\n"
     ]
    }
   ],
   "source": [
    "print(f\"ATE 95% CI:\", (np.percentile(ates, 2.5), np.percentile(ates, 97.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.625413Z",
     "start_time": "2023-03-14T11:06:30.502013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(ates, kde=False)\n",
    "plt.vlines(np.percentile(ates, 2.5), 0, 20, linestyles=\"dotted\")\n",
    "plt.vlines(np.percentile(ates, 97.5), 0, 20, linestyles=\"dotted\", label=\"95% CI\")\n",
    "plt.title(\"ATE Bootstrap Distribution\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que tivemos uma ideia do estimador duplamente robusto, vamos examinar por que ele é tão bom. Primeiro, é chamado de duplamente robusto porque só exige que um dos modelos, $\\hat{P}(x)$ ou $\\hat{\\mu}(x)$, esteja corretamente especificado. Para entender isso, pegue a primeira parte que estima $E[Y_1]$ e analise-a cuidadosamente.\n",
    "\n",
    "$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_i(Y_i - \\hat{\\mu_1}(X_i))}{\\hat{P}(X_i)} + \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$\n",
    "\n",
    "Suponha que $\\hat{\\mu_1}(x)$ seja correto. Se o modelo de pontuação de propensão estiver errado, não precisamos nos preocupar. Isso porque, se $\\hat{\\mu_1}(x)$ estiver correto, então $E[T_i(Y_i - \\hat{\\mu_1}(X_i))]=0$. Isso ocorre porque a multiplicação por $T_i$ seleciona apenas os tratados, e o resíduo de $\\hat{\\mu_1}$ nos tratados tem, por definição, média zero. Isso faz com que o conjunto inteiro se reduza a $\\hat{\\mu_1}(X_i)$, que é a estimativa correta de $E[Y_1]$ por hipótese. Portanto, você vê que, ao estar correto, $\\hat{\\mu_1}(X_i)$ elimina a relevância do modelo de escore de propensão. Podemos aplicar o mesmo raciocínio para compreender o estimador de $E[Y_0]$.\n",
    "\n",
    "Mas não confie apenas em minhas palavras. Deixe o código mostrar o caminho! No estimador a seguir, substituí a regressão logística que estima o escore de propensão por uma variável aleatória uniforme que varia de 0.1 a 0.9 (não quero pesos muito pequenos aumentando a variância do escore de propensão). Como isso é aleatório, não tem esse modelo ser um bom modelo de escore de propensão, mas veremos que o estimador duplamente robusto ainda consegue produzir uma estimativa muito próxima daquela obtida quando o escore de propensão foi estimado com regressão logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.631039Z",
     "start_time": "2023-03-14T11:06:30.626680Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "def doubly_robust_wrong_ps(df, X, T, Y):\n",
    "    # wrong PS model\n",
    "    np.random.seed(654)\n",
    "    ps = np.random.uniform(0.1, 0.9, df.shape[0])\n",
    "    mu0 = LinearRegression().fit(df.query(f\"{T}==0\")[X], df.query(f\"{T}==0\")[Y]).predict(df[X])\n",
    "    mu1 = LinearRegression().fit(df.query(f\"{T}==1\")[X], df.query(f\"{T}==1\")[Y]).predict(df[X])\n",
    "    return (\n",
    "        np.mean(df[T]*(df[Y] - mu1)/ps + mu1) -\n",
    "        np.mean((1-df[T])*(df[Y] - mu0)/(1-ps) + mu0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:30.693635Z",
     "start_time": "2023-03-14T11:06:30.632597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3797369830995927"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubly_robust_wrong_ps(data_with_categ, X, T, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizarmos a técnica de amostras com reposição, podemos observar que a variância é ligeiramente maior do que quando o escore de propensão foi estimado com regressão logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:42.860551Z",
     "start_time": "2023-03-14T11:06:30.695579Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(88)\n",
    "parallel_fn = delayed(doubly_robust_wrong_ps)\n",
    "wrong_ps = Parallel(n_jobs=4)(parallel_fn(data_with_categ.sample(frac=1, replace=True), X, T, Y)\n",
    "                              for _ in range(bootstrap_sample))\n",
    "wrong_ps = np.array(wrong_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:42.865351Z",
     "start_time": "2023-03-14T11:06:42.861924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ATE 95% CI: (0.35364752721776144, 0.41978441342477585)\n",
      "Wrong PS ATE 95% CI: (0.33806443306747086, 0.4335673822553228)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original ATE 95% CI:\", (np.percentile(ates, 2.5), np.percentile(ates, 97.5)))\n",
    "\n",
    "print(f\"Wrong PS ATE 95% CI:\", (np.percentile(wrong_ps, 2.5), np.percentile(wrong_ps, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, comprometer a pontuação de propensão gera ATEs ligeiramente diferentes, mas não muito. Isso abrange o caso em que o modelo de propensão está errado, mas o modelo de resultado está correto. E quanto à outra situação? Vamos mais uma vez analisar cuidadosamente a primeira parte do estimador, mas vamos rearranjar alguns termos.\n",
    "\n",
    "$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_i(Y_i - \\hat{\\mu_1}(X_i))}{\\hat{P}(X_i)} + \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$\n",
    "\n",
    "$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_iY_i}{\\hat{P}(X_i)} - \\dfrac{T_i\\hat{\\mu_1}(X_i)}{\\hat{P}(X_i)} + \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$\n",
    "\n",
    "$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_iY_i}{\\hat{P}(X_i)} - \\bigg(\\dfrac{T_i}{\\hat{P}(X_i)} - 1\\bigg) \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$\n",
    "\n",
    "$\n",
    "\\hat{E}[Y_1] = \\frac{1}{N}\\sum \\bigg( \\dfrac{T_iY_i}{\\hat{P}(X_i)} - \\bigg(\\dfrac{T_i - \\hat{P}(X_i)}{\\hat{P}(X_i)}\\bigg) \\hat{\\mu_1}(X_i) \\bigg)\n",
    "$\n",
    "\n",
    "Agora, suponha que o escore de propensão $\\hat{P}(X_i)$ esteja corretamente especificado. Nesse caso, $E[T_i - \\hat{P}(X_i)]=0$, o que elimina a parte dependente de $\\hat{\\mu_1}(X_i)$. Isso faz com que o estimador duplamente robusto se reduza ao estimador de ponderação pelo escore de propensão $\\frac{T_iY_i}{\\hat{P}(X_i)}$, que é correto por hipótese. Portanto, mesmo que $\\hat{\\mu_1}(X_i)$ esteja incorreto, o estimador ainda será correto, desde que o escore de propensão esteja corretamente especificado.\n",
    "\n",
    "Mais uma vez, se você confia mais em código do que em fórmulas, aqui está a verificação prática. No código abaixo, substituí ambos os modelos de regressão por uma variável normal aleatória. Não há dúvida de que $\\hat{\\mu}(X_i)$ **não está corretamente especificado**. Ainda assim, veremos que a estimação duplamente robusta ainda consegue recuperar o mesmo $\\hat{ATE}$ de cerca de 0.38 que vimos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:42.869724Z",
     "start_time": "2023-03-14T11:06:42.866481Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "def doubly_robust_wrong_model(df, X, T, Y):\n",
    "    np.random.seed(654)\n",
    "    ps = LogisticRegression(C=1e6, max_iter=1000).fit(df[X], df[T]).predict_proba(df[X])[:, 1]\n",
    "    \n",
    "    # wrong mu(x) model\n",
    "    mu0 = np.random.normal(0, 1, df.shape[0])\n",
    "    mu1 = np.random.normal(0, 1, df.shape[0])\n",
    "    return (\n",
    "        np.mean(df[T]*(df[Y] - mu1)/ps + mu1) -\n",
    "        np.mean((1-df[T])*(df[Y] - mu0)/(1-ps) + mu0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:06:43.004865Z",
     "start_time": "2023-03-14T11:06:42.871233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39811864040982625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doubly_robust_wrong_model(data_with_categ, X, T, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez, podemos usar a técnica de amostras com reposição e observar que a variância é apenas ligeiramente maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:07:09.710264Z",
     "start_time": "2023-03-14T11:06:43.006264Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(88)\n",
    "parallel_fn = delayed(doubly_robust_wrong_model)\n",
    "wrong_mux = Parallel(n_jobs=4)(parallel_fn(data_with_categ.sample(frac=1, replace=True), X, T, Y)\n",
    "                               for _ in range(bootstrap_sample))\n",
    "wrong_mux = np.array(wrong_mux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-14T11:07:09.715084Z",
     "start_time": "2023-03-14T11:07:09.711724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ATE 95% CI: (0.35364752721776144, 0.41978441342477585)\n",
      "Wrong Mu ATE 95% CI: (0.33863822614929406, 0.433173164584189)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original ATE 95% CI:\", (np.percentile(ates, 2.5), np.percentile(ates, 97.5)))\n",
    "print(f\"Wrong Mu ATE 95% CI:\", (np.percentile(wrong_mux, 2.5), np.percentile(wrong_mux, 97.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez, alterar apenas o modelo da média condicional gera apenas uma ATE ligeiramente diferente. Espero tê-lo convencido sobre o poder da estimação duplamente robusta. Sua magia acontece porque, na inferência causal, há duas maneiras de remover o viés de nossas estimativas causais: ou modelamos o mecanismo de tratamento ou o mecanismo de resultado. Se um desses modelos estiver correto, você está pronto para prosseguir.\n",
    "\n",
    "Uma ressalva é que, na prática, é muito difícil modelar precisamente qualquer um deles. Frequentemente, o que acaba acontecendo é que nem o escore de propensão nem o modelo de resultado são 100% corretos. Ambos estão errados, mas de maneiras diferentes. Quando isso acontece, ainda não está exatamente definido [\\[1\\]](https://www.stat.cmu.edu/~ryantibs/journalclub/kang_2007.pdf) [\\[2\\]](https://arxiv.org/pdf/0804.2969.pdf) [\\[3\\]](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2798744/) se é melhor usar um único modelo ou a estimação duplamente robusta. Quanto a mim, ainda gosto de usá-los porque, pelo menos, me dá duas possibilidades de estar correto.\n",
    "\n",
    "\n",
    "## Conceitos-chave\n",
    "\n",
    "Aqui, vimos uma maneira simples de combinar a regressão linear com a pontuação de propensão para produzir um estimador duplamente robusto. Este estimador recebe esse nome porque requer apenas que um dos modelos esteja correto. Se o modelo de escore de propensão estiver correto, poderemos identificar o efeito causal mesmo que o modelo de resultado esteja errado. Por outro lado, se o modelo de resultado estiver correto, também poderemos identificar o efeito causal mesmo que o modelo de escore de propensão esteja errado.\n",
    "\n",
    "## Referências\n",
    "\n",
    "Gosto de pensar nesta série inteira como uma homenagem a Joshua Angrist, Alberto Abadie e Christopher Walters por sua incrível aula de Econometria. A maioria das ideias aqui foram tiradas de suas aulas na *American Economic Association*. Assisti-las é o que está me mantendo são durante este difícil ano de 2020.\n",
    "* [Cross-Section Econometrics](https://www.aeaweb.org/conference/cont-ed/2017-webcasts)\n",
    "* [Mastering Mostly Harmless Econometrics](https://www.aeaweb.org/conference/cont-ed/2020-webcasts)\n",
    "\n",
    "Também gostaria de referenciar os livros incríveis de Angrist. Eles me mostraram que Econometria, ou 'Métricas, como eles chamam, não é apenas extremamente útil, mas também profundamente divertida.\n",
    "\n",
    "* [Mostly Harmless Econometrics](https://www.mostlyharmlesseconometrics.com/)\n",
    "* [Mastering 'Metrics](https://www.masteringmetrics.com/)\n",
    "\n",
    "Finalmente, gostaria de referenciar o livro de Miguel Hernan e Jamie Robins. Tem sido meu fiel companheiro nas questões mais espinhosas de inferência causal que tive que responder.\n",
    "\n",
    "* [Causal Inference Book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)\n",
    "\n",
    "Os dados que utilizamos foram retirados do artigo [Estimating Treatment Effects with Causal Forests: An Application](https://arxiv.org/pdf/1902.07409.pdf), de Susan Athey e Stefan Wager.\n",
    "\n",
    "![img](./data/img/poetry.png)\n",
    "\n",
    "## Contribua\n",
    "\n",
    "\"Inferência Causal para os Corajosos e Verdadeiros\" é um material de código aberto sobre inferência causal, a estatística da ciência. Seu objetivo é ser acessível monetariamente e intelectualmente. Ele utiliza apenas software gratuito baseado em Python.\n",
    "Se você encontrou valor neste livro e deseja apoiá-lo, por favor, vá para o [Patreon](https://www.patreon.com/causal_inference_for_the_brave_and_true). Se você não estiver pronto para contribuir financeiramente, também pode ajudar corrigindo erros, sugerindo edições ou dando feedback sobre trechos que não compreendeu. Acesse o repositório do livro e abra uma issue na [versão em inglês](https://github.com/matheusfacure/python-causality-handbook/issues) ou na [versão em português](https://github.com/rdemarqui/python-causality-handbook-ptbr/issues). Por fim, se você gostou deste conteúdo, compartilhe com outras pessoas que possam achar útil e dê uma estrela no GitHub na [versão em inglês](https://github.com/matheusfacure/python-causality-handbook/stargazers) e na [versão em português](https://github.com/rdemarqui/python-causality-handbook-ptbr/stargazers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"11-Propensity-Score.ipynb\"><-- Anterior</a>  \n",
    "<a href=\"00-Summary.ipynb\">| Sumário |</a>  \n",
    "<a href=\"13-Difference-in-Differences.ipynb\">Próximo --></a>  \n",
    "\n",
    "<a href=\"https://matheusfacure.github.io/python-causality-handbook/12-Doubly-Robust-Estimation.html\">[12 - Doubly Robust Estimation]</a>  \n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
