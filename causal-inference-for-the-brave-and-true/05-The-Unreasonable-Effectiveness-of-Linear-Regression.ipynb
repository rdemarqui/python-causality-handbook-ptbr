{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - A Eficácia Surpreendente da Regressão Linear\n",
    "\n",
    "\n",
    "## Tudo o Que Você Precisa é de Regressão\n",
    "\n",
    "Ao lidar com inferência causal, vimos como existem dois resultados potenciais para cada indivíduo: $Y_0$ é o resultado que o indivíduo teria se não recebesse o tratamento e $Y_1$ é o resultado se ele recebesse o tratamento. O ato de definir o tratamento $T$ como 0 ou 1 materializa um dos resultados potenciais e torna impossível para nós conhecermos o outro. Isso leva ao fato de que o efeito do tratamento individual $\\tau_i = Y_{1i} - Y_{0i}$ é desconhecido. \n",
    "\n",
    "$\n",
    "Y_i = Y_{0i} + T_i(Y_{1i} - Y_{0i}) = Y_{0i}(1-T_i) + T_i Y_{1i}\n",
    "$\n",
    "\n",
    "Então, por enquanto, vamos nos concentrar na tarefa mais simples de estimar o efeito causal médio. Com isso em mente, estamos aceitando o fato de que algumas pessoas respondem melhor do que outras ao tratamento, mas também estamos aceitando que não podemos saber quem são elas. Em vez disso, vamos apenas tentar ver se o tratamento funciona, **na média**.\n",
    "\n",
    "$\n",
    "ATE = E[Y_1 - Y_0]\n",
    "$\n",
    "\n",
    "Isso nos dará um modelo simplificado, com um efeito de tratamento constante $Y_{1i} = Y_{0i} + \\kappa$. Se $\\kappa$ for positivo, diremos que o tratamento tem, em média, um efeito positivo. Mesmo que algumas pessoas reajam mal a ele, em média, o impacto será positivo.\n",
    "\n",
    "Vamos também lembrar que não podemos simplesmente estimar $E[Y_1 - Y_0]$ com a diferença nas médias $E[Y|T=1] - E[Y|T=0]$ devido ao viés. O viés surge frequentemente quando os tratados e não tratados são diferentes por razões outras que não o próprio tratamento. Uma maneira de ver isso é em como eles diferem no resultado potencial $Y_0$\n",
    "\n",
    "$\n",
    "E[Y|T=1] - E[Y|T=0] = \\underbrace{E[Y_1 - Y_0|T=1]}_{ATET} + \\underbrace{\\{ E[Y_0|T=1] - E[Y_0|T=0]\\}}_{BIAS}\n",
    "$\n",
    "\n",
    "Anteriormente, vimos como podemos eliminar o viés com Experimentos Aleatórios, ou **Ensaio Controlado Randomizado** (ECR), como às vezes são chamados. O ECR força os tratados e os não tratados a serem iguais, e é por isso que o viés desaparece. Também vimos como colocar níveis de incerteza em torno de nossas estimativas para o efeito do tratamento. Nomeadamente, olhamos para o caso de aulas online versus presenciais, onde $T=0$ representa aulas presenciais e $T=1$ representa aulas online. Os estudantes foram aleatoriamente designados para um desses 2 tipos de aulas e, em seguida, seu desempenho em um exame foi avaliado. Construímos uma função de teste A/B que poderia comparar ambos os grupos, fornecer o efeito médio do tratamento e até colocar um intervalo de confiança em torno dele.\n",
    "\n",
    "Now, it's time to see that we can do all of that with the workhorse of causal inference: **Linear Regression**! Think of it this way. If comparing treated and untreated means was an apple for dessert, linear regression would be cold and creamy tiramisu. Or if comparing treated and untreated is a sad and old loaf of white wonder bread, linear regression would be a crusty, soft crumb country loaf sourdough baked by Chad Robertson himself.\n",
    "\n",
    "Agora, é hora de ver que podemos fazer tudo isso com a ferramenta central da inferência causal: **Regressão Linear**! Pense desta forma. Se comparar médias de tratados e não tratados fosse uma maçã de sobremesa, a regressão linear seria um tiramisu gelado e cremoso. Ou se comparar tratados e não tratados fosse um triste e velho pão de forma branco, a regressão linear seria um pão de fermento natural crocante e macio, assado pelo próprio Chad Robertson.\n",
    "\n",
    "![img](./data/img/linear-regression/you_vs.png)\n",
    "\n",
    "Vamos ver como essa beleza funciona. No código abaixo, queremos executar exatamente a mesma análise de comparação entre aulas online e presenciais. Mas, em vez de fazer toda aquela matemática de intervalos de confiança, nós simplesmente executamos uma regressão. Mais especificamente, estimamos o seguinte modelo:\n",
    "\n",
    "$\n",
    "exam_i = \\beta_0 + \\kappa \\ Online_i + u_i\n",
    "$\n",
    "\n",
    "Isso significa que estamos modelando o resultado do exame como uma linha de base $\\beta_0$ mais $\\kappa$ se a aula for online. Claro, o resultado do exame é influenciado por variáveis adicionais (como o humor do aluno no dia do exame, horas estudadas e assim por diante). Mas não estamos realmente interessados em entender essas relações. Então, em vez disso, usamos o termo $u_i$ para representar tudo mais que não nos importa. Isso é chamado de erro do modelo.\n",
    "\n",
    "Note que $Online$ é a indicação do nosso tratamento e, portanto, uma variável *dummy*. Ela é zero quando o tratamento é presencial e 1 se for online. Com isso em mente, podemos ver que a regressão linear irá recuperar $E[Y|T=0] = \\beta_0$ e $E[Y|T=1] = \\beta_0 + \\kappa$. $\\kappa$ será o nosso ATE (Efeito de Tratamento Médio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import graphviz as gr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   78.5475</td> <td>    1.113</td> <td>   70.563</td> <td> 0.000</td> <td>   76.353</td> <td>   80.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>format_ol</th> <td>   -4.9122</td> <td>    1.680</td> <td>   -2.925</td> <td> 0.004</td> <td>   -8.223</td> <td>   -1.601</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/online_classroom.csv\").query(\"format_blended==0\")\n",
    "\n",
    "result = smf.ols('falsexam ~ format_ol', data=data).fit()\n",
    "result.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso é realmente incrível. Não estamos apenas aptos a estimar o ATE, mas também obtemos, gratuitamente, intervalos de confiança e valores-P! Além disso, podemos ver que a regressão está fazendo exatamente o que deveria fazer: comparar $E[Y|T=0]$ e $E[Y|T=1]$. A interseção é exatamente a média da amostra quando $T=0$, $E[Y|T=0]$, e o coeficiente do formato online é exatamente a diferença na média das amostras $E[Y|T=1] - E[Y|T=0]$. Não confia em mim? Sem problema. Você pode ver por si mesmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_ol\n",
       "0    78.547485\n",
       "1    73.635263\n",
       "Name: falsexam, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data\n",
    " .groupby(\"format_ol\")\n",
    " [\"falsexam\"]\n",
    " .mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado. Se você adicionar ao intercepto o ATE, ou seja, a estimativa do parâmetro do formato online, você obterá a média da amostra para os tratados: $78.5475 + (-4.9122) = 73.635263$.\n",
    "\n",
    "## Teoria da Regressão\n",
    "\n",
    "Não pretendo me aprofundar muito em como a regressão linear é construída e estimada. No entanto, um pouco de teoria ajudará bastante a explicar seu poder na inferência causal. Primeiramente, a regressão resolve um problema teórico de melhor predição linear. Seja $\\beta^*$ um vetor de parâmetros:\n",
    "\n",
    "$\n",
    "\\beta^* =\\underset{\\beta}{argmin} \\ E[(Y_i - X_i'\\beta)^2]\n",
    "$\n",
    "\n",
    "A regressão linear encontra os parâmetros que minimizam o erro quadrático médio (MSE, do inglês Mean Squared Error).\n",
    "\n",
    "Se você diferenciar isso e igualar a zero, encontrará que a solução linear para este problema é dada por\n",
    "\n",
    "$\n",
    "\\beta^* = E[X_i'X_i]^{-1}E[X_i' Y_i]\n",
    "$\n",
    "\n",
    "Podemos estimar este beta usando o equivalente da amostra:\n",
    "\n",
    "$\n",
    "\\hat{\\beta} = (X'X)^{-1}X' Y\n",
    "$\n",
    "\n",
    "Mas não acredite apenas na minha palavra. Se você é uma daquelas pessoas que entende melhor códigos do que fórmulas, tente por si mesmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.9122215 , 78.54748458])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[[\"format_ol\"]].assign(intercep=1)\n",
    "y = data[\"falsexam\"]\n",
    "\n",
    "def regress(y, X): \n",
    "    return np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "\n",
    "beta = regress(y, X)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As fórmulas acima são bastante gerais. No entanto, vale a pena estudar o caso em que temos apenas um regressor. Na inferência causal, muitas vezes queremos estimar o impacto causal de uma variável $T$ em um resultado $y$. Então, usamos a regressão com essa única variável para estimar esse efeito. Mesmo que incluamos outras variáveis no modelo, elas geralmente são apenas auxiliares. Adicionar outras variáveis pode nos ajudar a estimar o efeito causal do tratamento, mas não estamos muito interessados em estimar seus parâmetros.\n",
    "\n",
    "Com uma única variável regressora $T$, o parâmetro associado a ela será dado por\n",
    "\n",
    "$\n",
    "\\beta_1 = \\dfrac{Cov(Y_i, T_i)}{Var(T_i)} \n",
    "$\n",
    "\n",
    "Se $T$ for atribuída aleatoriamente, $\\beta_1$ é o ATE (Efeito de Tratamento Médio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.91222149822695"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kapa = data[\"falsexam\"].cov(data[\"format_ol\"]) / data[\"format_ol\"].var()\n",
    "kapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tivermos mais de um regressor, podemos estender a fórmula a seguir para acomodar isso. Digamos que essas outras variáveis são apenas auxiliares e que estamos verdadeiramente interessados apenas em estimar o parâmetro $\\kappa$ associado a $T$.\n",
    "\n",
    "$\n",
    "y_i = \\beta_0 + \\kappa T_i + \\beta_1 X_{1i} + ... +\\beta_k X_{ki} + u_i\n",
    "$\n",
    "\n",
    "$\\kappa$ pode ser obtido com a seguinte fórmula\n",
    "\n",
    "$\n",
    "\\kappa = \\dfrac{Cov(Y_i, \\tilde{T_i})}{Var(\\tilde{T_i})} \n",
    "$\n",
    "\n",
    "onde $\\tilde{T_i}$ é o resíduo de uma regressão de $T_i$ em todas as outras covariáveis $X_{1i}, ..., X_{ki}$. Agora, vamos apreciar o quão legal é isso. Significa que o coeficiente de uma regressão multivariada é o coeficiente bivariado do mesmo regressor **após levar em conta o efeito de outras variáveis no modelo**. Em termos de inferência causal, $\\kappa$ é o coeficiente bivariado de $T$ depois de ter usado todas as outras variáveis para prever isso.\n",
    "\n",
    "Isso tem uma intuição interessante por trás. Se podemos prever $T$ usando outras variáveis, significa que não é aleatória. No entanto, podemos fazer com que $T$ seja tão boa quanto aleatória uma vez que controlamos para outras variáveis disponíveis. Para fazer isso, usamos a regressão linear para prever a partir das outras variáveis e depois pegamos os resíduos dessa regressão $\\tilde{T}$. Por definição, $\\tilde{T}$ não pode ser previsto pelas outras variáveis $X$ que já usamos para prever $T$. De forma bastante elegante, $\\tilde{T}$ é uma versão do tratamento que não está associada a nenhuma outra variável em $X$.\n",
    "\n",
    "A propósito, isso também é uma propriedade da regressão linear. Os resíduos são sempre ortogonais ou não correlacionados com qualquer uma das variáveis no modelo que os criou:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonality imply that the dot product is zero: [7.81597009e-13 4.63984406e-12]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_ol</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>format_ol</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-9.419033e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>-9.419033e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              format_ol             e\n",
       "format_ol  1.000000e+00 -9.419033e-16\n",
       "e         -9.419033e-16  1.000000e+00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = y - X.dot(beta)\n",
    "print(\"Orthogonality imply that the dot product is zero:\", np.dot(e, X))\n",
    "X[[\"format_ol\"]].assign(e=e).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o que é ainda mais interessante é que essas propriedades não dependem de nada! São verdades matemáticas, independentemente de como seus dados se parecem.\n",
    "\n",
    "## Regressão para Dados Não Aleatórios\n",
    "\n",
    "Até agora, trabalhamos com dados de experimentos aleatórios, mas, como sabemos, esses dados são difíceis de obter. Experimentos são muito caros para conduzir ou simplesmente inviáveis. É muito difícil convencer a McKinsey & Co. a fornecer seus serviços gratuitamente de forma aleatória para que possamos, de uma vez por todas, distinguir o valor que seus serviços de consultoria trazem do fato de que as empresas que podem pagar por eles já são muito bem-sucedidas.\n",
    "\n",
    "Por essa razão, agora vamos nos aprofundar em dados não aleatórios ou observacionais. No exemplo a seguir, tentaremos estimar o impacto de um ano adicional de educação no salário por hora. Como você deve ter adivinhado, é extremamente difícil conduzir um experimento com educação. Você não pode simplesmente randomizar pessoas para terem 4, 8 ou 12 anos de educação. Neste caso, os dados observacionais são tudo que temos.\n",
    "\n",
    "Primeiro, vamos estimar um modelo bem simples. Vamos fazer a regressão dos salários por hora em logaritmo em função dos anos de educação. Usamos logaritmos aqui para que nossas estimativas de parâmetros tenham uma interpretação em porcentagem (se você nunca ouviu falar sobre essas propriedades incríveis do logaritmo e quer saber por que isso acontece, confira [este link](https://stats.stackexchange.com/questions/244199/why-is-it-that-natural-log-changes-are-percentage-changes-what-is-about-logs-th)). Com isso, seremos capazes de dizer que 1 ano a mais de educação resulta em um aumento de x% no salário.\n",
    "\n",
    "$\n",
    "log(hwage)_i = \\beta_0 + \\beta_1 educ_i + u_i\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.3071</td> <td>    0.104</td> <td>   22.089</td> <td> 0.000</td> <td>    2.102</td> <td>    2.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0536</td> <td>    0.008</td> <td>    7.114</td> <td> 0.000</td> <td>    0.039</td> <td>    0.068</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage = pd.read_csv(\"./data/wage.csv\").dropna()\n",
    "model_1 = smf.ols('np.log(hwage) ~ educ', data=wage.assign(hwage=wage[\"wage\"]/wage[\"hours\"])).fit()\n",
    "model_1.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estimativa de $\\beta_1$ é 0.0536, com um intervalo de confiança de 95% de (0.039, 0.068). Isso significa que este modelo prevê que os salários aumentarão cerca de 5,3% para cada ano adicional de educação. Esse aumento percentual está alinhado com a crença de que a educação impacta os salários de forma exponencial: esperamos que ir de 11 para 12 anos de educação (média para concluir o ensino médio) seja menos recompensador do que ir de 14 para 16 anos (média para concluir a faculdade)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use(\"fivethirtyeight\")\n",
    "\n",
    "x = np.array(range(5, 20))\n",
    "plt.plot(x, np.exp(model_1.params[\"Intercept\"] + model_1.params[\"educ\"] * x))\n",
    "plt.xlabel(\"Years of Education\")\n",
    "plt.ylabel(\"Hourly Wage\")\n",
    "plt.title(\"Impact of Education on Hourly Wage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claro, não é porque podemos estimar este modelo simples que ele esteja correto. Observe como fui cuidadoso com minhas palavras ao dizer que ele **prevê** o salário a partir da educação. Nunca disse que essa previsão era causal. Na verdade, até agora, você provavelmente tem razões muito sérias para acreditar que este modelo está enviesado. Como nossos dados não vieram de um experimento aleatório, não sabemos se aqueles que receberam mais educação são comparáveis aos que receberam menos. Indo ainda mais longe, com base em nosso entendimento de como o mundo funciona, estamos muito certos de que eles não são comparáveis. Nomeadamente, podemos argumentar que aqueles com mais anos de educação provavelmente têm pais mais ricos, e que o aumento que estamos vendo nos salários à medida que aumentamos a educação é apenas um reflexo de como a riqueza familiar está associada a mais anos de educação. Colocando em termos matemáticos, pensamos que $E[Y_0|T=0] < E[Y_0|T=1]$, ou seja, aqueles com mais educação teriam uma renda maior de qualquer maneira, mesmo sem tantos anos de educação. Se você for realmente pessimista sobre educação, pode argumentar que ela pode até mesmo *reduzir* os salários ao manter as pessoas fora do mercado de trabalho e diminuir sua experiência.\n",
    "\n",
    "Felizmente, em nossos dados, temos acesso a muitas outras variáveis. Podemos ver a educação dos pais `meduc`, `feduc`, a pontuação de `QI` da pessoa, o número de anos de experiência `exper` e o tempo de permanência da pessoa em sua atual empresa `tenure`. Até temos algumas variáveis fictícias para casamento e etnia negra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage</th>\n",
       "      <th>hours</th>\n",
       "      <th>lhwage</th>\n",
       "      <th>IQ</th>\n",
       "      <th>educ</th>\n",
       "      <th>exper</th>\n",
       "      <th>tenure</th>\n",
       "      <th>age</th>\n",
       "      <th>married</th>\n",
       "      <th>black</th>\n",
       "      <th>south</th>\n",
       "      <th>urban</th>\n",
       "      <th>sibs</th>\n",
       "      <th>brthord</th>\n",
       "      <th>meduc</th>\n",
       "      <th>feduc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>769</td>\n",
       "      <td>40</td>\n",
       "      <td>2.956212</td>\n",
       "      <td>93</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>825</td>\n",
       "      <td>40</td>\n",
       "      <td>3.026504</td>\n",
       "      <td>108</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650</td>\n",
       "      <td>40</td>\n",
       "      <td>2.788093</td>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562</td>\n",
       "      <td>40</td>\n",
       "      <td>2.642622</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>600</td>\n",
       "      <td>40</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>91</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage  hours    lhwage   IQ  educ  exper  tenure  age  married  black  \\\n",
       "0   769     40  2.956212   93    12     11       2   31        1      0   \n",
       "2   825     40  3.026504  108    14     11       9   33        1      0   \n",
       "3   650     40  2.788093   96    12     13       7   32        1      0   \n",
       "4   562     40  2.642622   74    11     14       5   34        1      0   \n",
       "6   600     40  2.708050   91    10     13       0   30        0      0   \n",
       "\n",
       "   south  urban  sibs  brthord  meduc  feduc  \n",
       "0      0      1     1      2.0    8.0    8.0  \n",
       "2      0      1     1      2.0   14.0   14.0  \n",
       "3      0      1     4      3.0   12.0   12.0  \n",
       "4      0      1    10      6.0    6.0   11.0  \n",
       "6      0      1     1      2.0    8.0    8.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos incluir todas essas variáveis extras em um modelo e estimá-lo:\n",
    "\n",
    "$\n",
    "log(hwage)_i = \\beta_0 + \\kappa \\ educ_i + \\pmb{\\beta}X_i + u_i\n",
    "$\n",
    "\n",
    "Para entender como isso ajuda com o problema de viés, vamos recapitular a decomposição bivariada da regressão linear multivariada.\n",
    "\n",
    "$\n",
    "\\kappa = \\dfrac{Cov(Y_i, \\tilde{T_i})}{Var(\\tilde{T_i})} \n",
    "$\n",
    "\n",
    "Esta fórmula diz que podemos prever `educ` a partir da educação dos pais, do QI, da experiência e assim por diante. Depois de fazer isso, ficaremos com uma versão de `educ`, $\\tilde{educ}$, que não está correlacionada com todas as variáveis incluídas anteriormente. Isso quebrará argumentos como \"pessoas que têm mais anos de educação têm isso porque têm QI mais alto. Não é o caso de a educação levar a salários mais altos. É apenas o caso de estar correlacionada com o QI, que é o que impulsiona os salários\". Bem, se incluirmos o QI no nosso modelo, então $\\kappa$ se torna o retorno de um ano adicional de educação mantendo o QI fixo. Faça uma pausa para entender o que isso implica. Mesmo que não possamos usar ensaios controlados randomizados para manter outros fatores iguais entre tratados e não tratados, a regressão pode fazer isso incluindo esses mesmos fatores no modelo, mesmo que os dados não sejam aleatórios!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041147191010057635"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controls = ['IQ', 'exper', 'tenure', 'age', 'married', 'black',\n",
    "            'south', 'urban', 'sibs', 'brthord', 'meduc', 'feduc']\n",
    "\n",
    "X = wage[controls].assign(intercep=1)\n",
    "t = wage[\"educ\"]\n",
    "y = wage[\"lhwage\"]\n",
    "\n",
    "beta_aux = regress(t, X)\n",
    "t_tilde = t - X.dot(beta_aux)\n",
    "\n",
    "kappa = t_tilde.cov(y) / t_tilde.var()\n",
    "kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este coeficiente que acabamos de estimar nos diz que, para pessoas com o mesmo QI, experiência, tempo de permanência, idade e assim por diante, devemos esperar que um ano adicional de educação esteja associado a um aumento de 4,11% no salário por hora. Isso confirma nossa suspeita de que o primeiro modelo simples com apenas `educ` estava enviesado. Também confirma que esse viés estava superestimando o impacto da educação. Uma vez que controlamos para outros fatores, o impacto estimado da educação caiu.\n",
    "\n",
    "Se formos mais sábios e usarmos software que outras pessoas escreveram em vez de codificar tudo por conta própria, podemos até colocar um intervalo de confiança em torno dessa estimativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.1156</td> <td>    0.232</td> <td>    4.802</td> <td> 0.000</td> <td>    0.659</td> <td>    1.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>educ</th>      <td>    0.0411</td> <td>    0.010</td> <td>    4.075</td> <td> 0.000</td> <td>    0.021</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IQ</th>        <td>    0.0038</td> <td>    0.001</td> <td>    2.794</td> <td> 0.005</td> <td>    0.001</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exper</th>     <td>    0.0153</td> <td>    0.005</td> <td>    3.032</td> <td> 0.003</td> <td>    0.005</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>    <td>    0.0094</td> <td>    0.003</td> <td>    2.836</td> <td> 0.005</td> <td>    0.003</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.0086</td> <td>    0.006</td> <td>    1.364</td> <td> 0.173</td> <td>   -0.004</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>   <td>    0.1795</td> <td>    0.053</td> <td>    3.415</td> <td> 0.001</td> <td>    0.076</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>black</th>     <td>   -0.0801</td> <td>    0.063</td> <td>   -1.263</td> <td> 0.207</td> <td>   -0.205</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>     <td>   -0.0397</td> <td>    0.035</td> <td>   -1.129</td> <td> 0.259</td> <td>   -0.109</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urban</th>     <td>    0.1926</td> <td>    0.036</td> <td>    5.418</td> <td> 0.000</td> <td>    0.123</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sibs</th>      <td>    0.0065</td> <td>    0.009</td> <td>    0.722</td> <td> 0.470</td> <td>   -0.011</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>brthord</th>   <td>   -0.0080</td> <td>    0.013</td> <td>   -0.604</td> <td> 0.546</td> <td>   -0.034</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>meduc</th>     <td>    0.0089</td> <td>    0.007</td> <td>    1.265</td> <td> 0.206</td> <td>   -0.005</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>feduc</th>     <td>    0.0069</td> <td>    0.006</td> <td>    1.113</td> <td> 0.266</td> <td>   -0.005</td> <td>    0.019</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = smf.ols('lhwage ~ educ +' + '+'.join(controls), data=wage).fit()\n",
    "model_2.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viés de Variável Omitida ou Confundimento\n",
    "\n",
    "A questão que permanece é: este parâmetro que estimamos é causal? Infelizmente, não podemos dizer com certeza. Podemos argumentar que o primeiro modelo simples que regrediu o salário sobre a educação provavelmente não é causal. Ele omite variáveis importantes que estão correlacionadas tanto com a educação quanto com os salários. Sem controlar por elas, o impacto estimado da educação também está capturando o impacto dessas outras variáveis que não foram incluídas no modelo.\n",
    "\n",
    "Para entender melhor como esse viés funciona, vamos supor que o modelo verdadeiro de como a educação afeta o salário seja algo assim\n",
    "\n",
    "$\n",
    "Wage_i = \\alpha + \\kappa \\ Educ_i + A_i'\\beta + u_i\n",
    "$\n",
    "\n",
    "o salário é afetado pela educação, que é medida pelo tamanho de $\\kappa$, e por fatores adicionais de habilidade, denotados como o vetor $A$. Se omitirmos a habilidade do nosso modelo, nossa estimativa para $\\kappa$ será assim:\n",
    "\n",
    "$\n",
    "\\dfrac{Cov(Wage_i, Educ_i)}{Var(Educ_i)} = \\kappa + \\beta'\\delta_{Ability}\n",
    "$\n",
    "\n",
    "onde $\\delta_{A}$ é o vetor de coeficientes da regressão de $Educ$ em $A$.\n",
    "\n",
    "O ponto chave aqui é que isso não será exatamente o $\\kappa$ que queremos. Em vez disso, vem com este termo extra irritante $\\beta'\\delta_{A}$. Este termo é o impacto do $A$ omitido no $Wage$, $\\beta$ vezes o impacto do omitido no incluído $Educ$. Isso é importante para os economistas a ponto de Joshua Angrist ter feito um mantra disso, para que os alunos possam recitá-lo em meditação:\n",
    "\n",
    "```\n",
    "\"Curta é igual a longa \n",
    "mais o efeito da omitida \n",
    "vezes a regressão da omitida na incluída\"\n",
    "```\n",
    "\n",
    "Aqui, a regressão curta é aquela que omite variáveis, enquanto a longa é aquela que as inclui. Essa fórmula ou mantra nos dá mais insights sobre a natureza do viés. Primeiro, o termo de viés será zero se as variáveis omitidas não tiverem impacto na variável dependente $Y$. Isso faz total sentido. Não preciso controlar por coisas que são irrelevantes para os salários ao tentar entender o impacto da educação neles (como a altura dos lírios do campo). Em segundo lugar, o termo de viés também será zero se as variáveis omitidas não tiverem impacto na variável de tratamento. Isso também faz sentido intuitivamente. Se tudo o que impacta a educação foi incluído no modelo, não há como o impacto estimado da educação estar misturado com uma correlação da educação em algo mais que também impacta os salários.\n",
    "\n",
    "![img](data/img/linear-regression/confused_cat.png)\n",
    "\n",
    "Para colocar de forma mais sucinta, dizemos que **não há Viés de Variável Omitida (OVB) se todas as variáveis de confundimento forem contabilizadas no modelo**. Também podemos aproveitar nosso conhecimento sobre gráficos causais aqui. Uma variável de confundimento é aquela que **causa tanto o tratamento quanto o resultado**. No exemplo do salário, o QI é um confundidor. Pessoas com QI alto tendem a completar mais anos de educação porque é mais fácil para elas, então podemos dizer que o QI causa a educação. Pessoas com QI alto também tendem a ser naturalmente mais produtivas e, consequentemente, têm salários mais altos, então o QI também causa o salário. Como os confundidores são variáveis que afetam tanto o tratamento quanto o resultado, marcamos eles com uma seta indo para T e Y. Aqui, eu os denotei com $W$. Também marquei a causalidade positiva com vermelho e a causalidade negativa com azul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"345pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 345.25 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 341.25,-184 341.25,4 -4,4\"/>\n",
       "<!-- W -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>W</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"69\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"69\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">W</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- W&#45;&gt;T -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>W&#45;&gt;T</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.47,-145.12C54.33,-136.56 47.88,-125.8 42.08,-116.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"44.93,-114.08 36.78,-107.31 38.93,-117.68 44.93,-114.08\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- W&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>W&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.28,-143.87C67.25,-119.67 65.38,-75.21 64.16,-46.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"67.65,-46.03 63.73,-36.19 60.65,-46.33 67.65,-46.03\"/>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n",
       "</g>\n",
       "<!-- IQ -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>IQ</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"161\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"161\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">IQ</text>\n",
       "</g>\n",
       "<!-- Educ -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Educ</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"148\" cy=\"-90\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"148\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Educ</text>\n",
       "</g>\n",
       "<!-- IQ&#45;&gt;Educ -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>IQ&#45;&gt;Educ</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M157.85,-144.05C156.42,-136.35 154.69,-127.03 153.08,-118.36\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"156.48,-117.47 151.21,-108.28 149.59,-118.75 156.48,-117.47\"/>\n",
       "</g>\n",
       "<!-- Wage -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Wage</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"161\" cy=\"-18\" rx=\"31.4\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"161\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Wage</text>\n",
       "</g>\n",
       "<!-- IQ&#45;&gt;Wage -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>IQ&#45;&gt;Wage</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M170.85,-144.97C176.51,-134.79 183.06,-121.1 186,-108 189.5,-92.39 189.5,-87.61 186,-72 183.9,-62.62 179.95,-52.95 175.79,-44.48\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"178.84,-42.74 171.11,-35.5 172.63,-45.98 178.84,-42.74\"/>\n",
       "</g>\n",
       "<!-- Educ&#45;&gt;Wage -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Educ&#45;&gt;Wage</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M151.15,-72.05C152.58,-64.35 154.31,-55.03 155.92,-46.36\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"159.41,-46.75 157.79,-36.28 152.52,-45.47 159.41,-46.75\"/>\n",
       "</g>\n",
       "<!-- Crime -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>Crime</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"295\" cy=\"-162\" rx=\"33.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"295\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Crime</text>\n",
       "</g>\n",
       "<!-- Police -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>Police</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"265\" cy=\"-90\" rx=\"32.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"265\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Police</text>\n",
       "</g>\n",
       "<!-- Crime&#45;&gt;Police -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>Crime&#45;&gt;Police</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M287.89,-144.41C284.43,-136.34 280.18,-126.43 276.29,-117.35\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"279.42,-115.77 272.27,-107.96 272.99,-118.53 279.42,-115.77\"/>\n",
       "</g>\n",
       "<!-- Violence -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>Violence</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"295\" cy=\"-18\" rx=\"42.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"295\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Violence</text>\n",
       "</g>\n",
       "<!-- Crime&#45;&gt;Violence -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>Crime&#45;&gt;Violence</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M299.46,-143.95C301.94,-133.63 304.75,-120.15 306,-108 307.63,-92.08 307.63,-87.92 306,-72 305.12,-63.46 303.47,-54.26 301.71,-45.96\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"305.08,-45.03 299.46,-36.05 298.26,-46.57 305.08,-45.03\"/>\n",
       "</g>\n",
       "<!-- Police&#45;&gt;Violence -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>Police&#45;&gt;Violence</title>\n",
       "<path fill=\"none\" stroke=\"blue\" d=\"M272.11,-72.41C275.57,-64.34 279.82,-54.43 283.71,-45.35\"/>\n",
       "<polygon fill=\"blue\" stroke=\"blue\" points=\"287.01,-46.53 287.73,-35.96 280.58,-43.77 287.01,-46.53\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1376f1da0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "\n",
    "g.edge(\"W\", \"T\"), g.edge(\"W\", \"Y\"), g.edge(\"T\", \"Y\")\n",
    "\n",
    "g.edge(\"IQ\", \"Educ\", color=\"red\"), g.edge(\"IQ\", \"Wage\", color=\"red\"), g.edge(\"Educ\", \"Wage\", color=\"red\")\n",
    "\n",
    "g.edge(\"Crime\", \"Police\", color=\"red\"), g.edge(\"Crime\", \"Violence\", color=\"red\"), \n",
    "g.edge(\"Police\", \"Violence\", color=\"blue\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráficos causais são excelentes para representar nossa compreensão do mundo e entender como o viés de confundimento funciona. Em nosso primeiro exemplo, temos um gráfico onde a educação causa o salário: mais educação leva a salários mais altos. No entanto, o QI também causa o salário e também causa a educação: um QI alto causa tanto mais educação quanto um salário mais alto. Se não considerarmos o QI em nosso modelo, parte de seu efeito sobre o salário fluirá através da correlação com a educação. Isso fará com que o impacto da educação pareça maior do que realmente é. Este é um exemplo de viés positivo.\n",
    "\n",
    "Apenas para dar outro exemplo, mas com viés negativo, considere o gráfico causal sobre o efeito da polícia na violência na cidade. O que normalmente vemos no mundo é que cidades com força policial maior também têm mais violência. Isso significa que a polícia está causando a violência? Bem, pode ser, não acho que seja relevante entrar nessa discussão aqui. Mas há também uma forte possibilidade de que haja uma variável de confundimento nos fazendo ver uma versão tendenciosa do impacto da polícia na violência. Pode ser que aumentar a força policial diminua a violência. No entanto, uma terceira variável, o crime, causa tanto mais violência quanto mais força policial. Se não a considerarmos, o impacto do crime na violência fluirá através da força policial, fazendo parecer que ela aumenta a violência. Este é um exemplo de viés negativo.\n",
    "\n",
    "Os gráficos causais também podem nos mostrar como tanto a regressão quanto os ensaios controlados randomizados são corretos para o viés de confundimento. Os ensaios controlados randomizados fazem isso ao romper a conexão do confundidor com a variável de tratamento. Ao tornar $T$ aleatório, por definição, nada pode causá-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"284pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 283.60 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 279.6,-112 279.6,4 -4,4\"/>\n",
       "<!-- W -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>W</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">W</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"80\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"80\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- W&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>W&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M38.76,-73.46C45.62,-64.4 54.42,-52.79 62.12,-42.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.02,-44.58 68.27,-34.49 59.44,-40.35 65.02,-44.58\"/>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M94.4,-72.05C92.25,-64.14 89.65,-54.54 87.24,-45.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.55,-44.52 84.56,-35.79 83.8,-46.36 90.55,-44.52\"/>\n",
       "</g>\n",
       "<!-- IQ -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>IQ</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"173\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"173\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">IQ</text>\n",
       "</g>\n",
       "<!-- Wage -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Wage</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"191\" cy=\"-18\" rx=\"31.4\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"191\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Wage</text>\n",
       "</g>\n",
       "<!-- IQ&#45;&gt;Wage -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>IQ&#45;&gt;Wage</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M177.36,-72.05C179.36,-64.26 181.79,-54.82 184.04,-46.08\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"187.46,-46.83 186.56,-36.28 180.68,-45.09 187.46,-46.83\"/>\n",
       "</g>\n",
       "<!-- Educ -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Educ</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"247\" cy=\"-90\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Educ</text>\n",
       "</g>\n",
       "<!-- Educ&#45;&gt;Wage -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>Educ&#45;&gt;Wage</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M234.57,-73.46C227.42,-64.53 218.29,-53.11 210.23,-43.04\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"212.76,-40.6 203.78,-34.98 207.3,-44.97 212.76,-40.6\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x13919eb00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "\n",
    "g.edge(\"W\", \"Y\"), g.edge(\"T\", \"Y\")\n",
    "\n",
    "g.edge(\"IQ\", \"Wage\", color=\"red\"), g.edge(\"Educ\", \"Wage\", color=\"red\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outro lado, a regressão faz isso comparando o efeito de $T$ enquanto mantém o confundidor $W$ fixado em um nível constante. Com a regressão, não é o caso de que W deixe de causar T e Y. É apenas que ele é mantido constante, para que não possa influenciar as mudanças em T e Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.44.1 (20200629.0846)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"297pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 297.39 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 293.39,-112 293.39,4 -4,4\"/>\n",
       "<!-- W=w -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>W=w</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"31.2\" cy=\"-90\" rx=\"31.4\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"31.2\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">W=w</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"107.2\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.2\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"107.2\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.2\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.2,-71.7C107.2,-63.98 107.2,-54.71 107.2,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.7,-46.1 107.2,-36.1 103.7,-46.1 110.7,-46.1\"/>\n",
       "</g>\n",
       "<!-- IQ=x -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>IQ=x</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"182.2\" cy=\"-90\" rx=\"29.8\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"182.2\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">IQ=x</text>\n",
       "</g>\n",
       "<!-- Educ -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>Educ</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"258.2\" cy=\"-90\" rx=\"28.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.2\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Educ</text>\n",
       "</g>\n",
       "<!-- Wage -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>Wage</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"258.2\" cy=\"-18\" rx=\"31.4\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.2\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Wage</text>\n",
       "</g>\n",
       "<!-- Educ&#45;&gt;Wage -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Educ&#45;&gt;Wage</title>\n",
       "<path fill=\"none\" stroke=\"red\" d=\"M258.2,-71.7C258.2,-63.98 258.2,-54.71 258.2,-46.11\"/>\n",
       "<polygon fill=\"red\" stroke=\"red\" points=\"261.7,-46.1 258.2,-36.1 254.7,-46.1 261.7,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1391ad128>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = gr.Digraph()\n",
    "\n",
    "g.node(\"W=w\"), g.edge(\"T\", \"Y\")\n",
    "g.node(\"IQ=x\"), g.edge(\"Educ\", \"Wage\", color=\"red\")\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, voltando à nossa pergunta, o parâmetro que estimamos para o impacto de \"educ\" no salário é causal? Sinto muito, mas isso dependerá de nossa capacidade de argumentar a favor ou contra o fato de que todos os confundidores foram incluídos no modelo. Pessoalmente, acredito que não foram. Por exemplo, não incluímos a riqueza familiar. Mesmo que tenhamos incluído a educação da família, isso só pode ser visto como um proxy para a riqueza. Também não consideramos fatores como ambição pessoal. Pode ser que a ambição seja o que causa tanto mais anos de educação quanto um salário mais alto, então ela é um confundidor. Isso é para mostrar que **a inferência causal com dados não aleatórios ou observacionais deve sempre ser feita com precaução**. Nunca podemos ter certeza de que todos os confundidores foram considerados.\n",
    "\n",
    "\n",
    "## Conceitos-chave\n",
    "\n",
    "Nós cobrimos muito terreno com a regressão. Vimos como a regressão pode ser usada para realizar testes A/B e como convenientemente nos fornece intervalos de confiança. Em seguida, estudamos como a regressão resolve um problema de previsão e é a melhor aproximação linear para a função de expectativa condicional (FEC). Também discutimos como, no caso bivariado, o coeficiente de tratamento da regressão é a covariância entre o tratamento e o resultado dividido pela variância do tratamento. Expandindo para o caso multivariado, descobrimos como a regressão nos dá uma interpretação de isolamento parcial do coeficiente de tratamento: ele pode ser interpretado como a forma como o resultado mudaria com o tratamento, mantendo todas as outras variáveis incluídas constantes. Isso é o que os economistas adoram se referir como *ceteris paribus*.\n",
    "\n",
    "Por fim, fizemos uma virada para entender o viés. Vimos como `Curta igual a longa mais o efeito da omitida vezes a regressão da omitida na incluída`. Isso lançou alguma luz sobre como o viés surge. Descobrimos que a fonte do viés de variável omitida é o confundimento: uma variável que afeta tanto o tratamento quanto o resultado. Por fim, usamos gráficos causais para ver como RCT e regressão corrigem o confundimento.\n",
    "\n",
    "## Referências\n",
    "\n",
    "Gosto de pensar nesta série inteira como uma homenagem a Joshua Angrist, Alberto Abadie e Christopher Walters por sua incrível aula de Econometria. A maioria das ideias aqui foram tiradas de suas aulas na *American Economic Association*. Assisti-las é o que está me mantendo são durante este difícil ano de 2020.\n",
    "* [Cross-Section Econometrics](https://www.aeaweb.org/conference/cont-ed/2017-webcasts)\n",
    "* [Mastering Mostly Harmless Econometrics](https://www.aeaweb.org/conference/cont-ed/2020-webcasts)\n",
    "\n",
    "Também gostaria de referenciar os livros incríveis de Angrist. Eles me mostraram que Econometria, ou 'Métricas, como eles chamam, não é apenas extremamente útil, mas também profundamente divertida.\n",
    "\n",
    "* [Mostly Harmless Econometrics](https://www.mostlyharmlesseconometrics.com/)\n",
    "* [Mastering 'Metrics](https://www.masteringmetrics.com/)\n",
    "\n",
    "Finalmente, gostaria de referenciar o livro de Miguel Hernan e Jamie Robins. Tem sido meu fiel companheiro nas questões mais espinhosas de inferência causal que tive que responder.\n",
    "\n",
    "* [Causal Inference Book](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)\n",
    "\n",
    "![img](./data/img/poetry.png)\n",
    "\n",
    "## Contribua\n",
    "\n",
    "\"Inferência Causal para os Corajosos e Verdadeiros\" é um material de código aberto sobre inferência causal, a estatística da ciência. Seu objetivo é ser acessível monetariamente e intelectualmente. Ele utiliza apenas software gratuito baseado em Python.\n",
    "Se você encontrou valor neste livro e deseja apoiá-lo, por favor, vá para o [Patreon](https://www.patreon.com/causal_inference_for_the_brave_and_true). Se você não estiver pronto para contribuir financeiramente, também pode ajudar corrigindo erros, sugerindo edições ou dando feedback sobre trechos que não compreendeu. Acesse o repositório do livro e abra uma issue na [versão em inglês](https://github.com/matheusfacure/python-causality-handbook/issues) ou na [versão em português](https://github.com/rdemarqui/python-causality-handbook-ptbr/issues). Por fim, se você gostou deste conteúdo, compartilhe com outras pessoas que possam achar útil e dê uma estrela no GitHub na [versão em inglês](https://github.com/matheusfacure/python-causality-handbook/stargazers) e na [versão em português](https://github.com/rdemarqui/python-causality-handbook-ptbr/stargazers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em> <b>Nota de Tradução: </b>[Variáveis dummy](https://pt.wikipedia.org/wiki/Vari%C3%A1vel_dummy_(estat%C3%ADstica)), também chamadas de fictícias, são variáveis criadas para representar uma variável com duas ou mais categorias. Esse conceito será mais explorado no próximo capitulo. </em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<a href=\"04-Graphical-Causal-Models.ipynb\"><-- Anterior</a>  \n",
    "<a href=\"00-Summary.ipynb\">| Sumário |</a>  \n",
    "<a href=\"06-Grouped-and-Dummy-Regression.ipynb\">Próximo --></a>  \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "causal-glory",
   "language": "python",
   "name": "causal-glory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
